
# ğŸ¯ **Project: AI-Generated Quiz Performance Dashboard (Beginner â†’ Pro)**

A real-world Big Data + Analytics project for your LMS where quizzes are AI-generated and student performance is analyzed deeply.

---

# âœ… **1. Detailed SRS (Software Requirement Specification)**

## **1.1 Project Overview**

Your LMS generates quizzes using AI (MCQ, subjective, difficulty-based).
This project analyzes:

* Student performance
* Difficulty distribution
* Time taken per question
* Per-topic mastery
* AI-generated question quality
* Predictive insights

Dashboard is for:
âœ” Teachers
âœ” Students
âœ” Admin/Organization

---

# **1.2 Functional Requirements**

### **FR-1: Ingest AI Quiz Metadata**

Each AI-generated quiz must store:

* quiz_id
* question_id
* generated_by_model
* difficulty_level
* bloom_level
* question_type

### **FR-2: Track Student Attempts**

Collect attempt-level events:

* student_id
* quiz_id
* question_id
* selected_option
* correct_option
* is_correct
* time_spent_seconds
* attempt_timestamp

### **FR-3: Generate Metrics**

System must compute:

* Score
* Accuracy
* Topic-wise performance
* Difficulty-wise accuracy
* Average time per question
* Weak areas
* Strength areas
* Bloom-level mastery

### **FR-4: Dashboards**

Dashboards must display:

* Per quiz analytics
* Per student analytics
* Class-level analytics
* Topic-wise heatmap
* Difficulty pyramid
* Speed vs accuracy graph
* Top 5 difficult questions from AI

### **FR-5: Insights & Alerts**

Insights must include:

* â€œStudent is weak in Algebra-Level-2â€
* â€œAI-generated questions too difficult this weekâ€
* â€œQuiz accuracy dropped by 25% since last versionâ€
* â€œStudents are taking too long on easy questionsâ€

---

# **1.3 Non-Functional Requirements**

* **Scalability:** Handle 10M question-attempt records/day
* **Performance:** Dashboard load < 2 sec
* **Security:** Mask student identifiable info
* **Reliability:** No data loss in ingestion pipeline
* **Accuracy:** Quiz scoring must match model-generated answer keys

---

# **1.4 Stakeholders**

* Students
* Teachers
* Admins
* Data engineers
* AI team
* LMS product managers

---

# ğŸš€ **2. Dataset Design**

---

# **Table 1 â€” ai_quiz_metadata (raw)**

| Field         | Type                     | Description                  |
| ------------- | ------------------------ | ---------------------------- |
| quiz_id       | string                   | Unique quiz                  |
| question_id   | string                   | Unique Q                     |
| generated_by  | string                   | e.g., GPT-4, Llama 3, Claude |
| difficulty    | enum(easy, medium, hard) |                              |
| topic         | string                   | e.g., Algebra                |
| bloom_level   | enum(L1â€“L6)              |                              |
| question_type | mcq, true/false, fillups |                              |
| created_at    | datetime                 |                              |

---

# **Table 2 â€” student_attempts (raw)**

| Field              | Type           |
| ------------------ | -------------- |
| attempt_id         | string         |
| student_id         | string         |
| quiz_id            | string         |
| question_id        | string         |
| selected_option    | string         |
| correct_option     | string         |
| is_correct         | boolean        |
| time_spent_seconds | int            |
| attempt_timestamp  | datetime       |
| device_type        | mobile/desktop |

---

# **Table 3 â€” quiz_summary (processed)**

| Field                | Description       |
| -------------------- | ----------------- |
| quiz_id              | Quiz              |
| total_questions      | Count             |
| avg_difficulty       | Weighted score    |
| avg_time             | Mean time         |
| overall_accuracy     | (correct / total) |
| most_difficult_topic | Topic             |
| bloom_distribution   | JSON              |
| top_wrong_questions  | Array             |

---

# **Table 4 â€” student_performance_summary**

| Field                   | Description   |
| ----------------------- | ------------- |
| student_id              | User          |
| quiz_id                 | Quiz          |
| score_percent           | 0â€“100         |
| accuracy                | correct/total |
| avg_time                | seconds       |
| weak_topics             | JSON          |
| strengths               | JSON          |
| bloom_mastery           | JSON          |
| difficulty_accuracy_map | JSON          |

---

# **Table 5 â€” class_level_analytics**

| Field                  | Description |
| ---------------------- | ----------- |
| class_id               | Class       |
| quiz_id                | Quiz        |
| avg_score              | Aggregate   |
| avg_accuracy           | Avg correct |
| difficulty_trend       | JSON        |
| question_quality_score | ML-based    |

---

---

# ğŸ“Š **3. Architecture Diagram**

```
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚     LMS Frontend       â”‚
                 â”‚  (Quiz Attempt Events) â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   Kafka Bus  â”‚
                       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚   ETL Pipeline (Airflow)â”‚
                  â”‚ PySpark / Pandas / DBT  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     Data Lake        â”‚
                    â”‚  S3 / MinIO / GCS    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Data Warehouse      â”‚
                    â”‚ BigQuery / Redshift   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                BI Dashboard                   â”‚
       â”‚ PowerBI / Tableau / Looker / Metabase / Superset â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ“ **4. Step-by-Step Tasks for the Intern**

---

## **Phase 1 â€” Beginner**

ğŸ“Œ Task 1: Explore dataset & create small sample CSV
ğŸ“Œ Task 2: Clean student_attempts dataset
ğŸ“Œ Task 3: Compute simple metrics

* Accuracy
* Time spent
* Score
  ğŸ“Œ Task 4: Plot
* Accuracy per quiz
* Time spent distribution
  ğŸ“Œ Task 5: SQL queries
* Top 10 difficult questions
* Average score per class
* Topic-wise accuracy

---

## **Phase 2 â€” Intermediate**

ğŸ“Œ Task 6: Build ETL script (Python Pandas)
ğŸ“Œ Task 7: Create Data Lake folder structure
ğŸ“Œ Task 8: DBT models

* quiz_summary
* student_performance_summary
  ğŸ“Œ Task 9: Build basic dashboards
* Quiz-level analytics
* Student-level insights

---

## **Phase 3 â€” Advanced**

ğŸ“Œ Task 10: Use PySpark for big datasets
ğŸ“Œ Task 11: Real-time quiz scoring ingestion
ğŸ“Œ Task 12: Build difficulty-trend graphs
ğŸ“Œ Task 13: Build ML model for question difficulty prediction
ğŸ“Œ Task 14: Personalized recommendation logic

---

## **Phase 4 â€” Pro**

ğŸ“Œ Task 15: Design complete real-time analytics system
ğŸ“Œ Task 16: Build complete dashboard using Metabase/PowerBI
ğŸ“Œ Task 17: Integrate dashboard into LMS (iframe or API)
ğŸ“Œ Task 18: Add anomaly alerts

* Sudden drop in accuracy
* Questions with high wrong-rate
  ğŸ“Œ Task 19: Question Quality Scoring ML model
  ğŸ“Œ Task 20: Full documentation + GitHub wiki

---

# ğŸ“ **5. GitHub Folder Structure**

```
ai-quiz-performance-dashboard/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â””â”€â”€ kafka_consumer.py
â”‚   â”œâ”€â”€ etl/
â”‚   â”‚   â”œâ”€â”€ quiz_summary.py
â”‚   â”‚   â”œâ”€â”€ student_performance.py
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”œâ”€â”€ accuracy_analysis.ipynb
â”‚   â”‚   â”œâ”€â”€ topic_trends.ipynb
â”‚   â””â”€â”€ ml/
â”‚       â””â”€â”€ question_difficulty_model.py
â”‚
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/
â”‚       â””â”€â”€ quiz_etl_dag.py
â”‚
â”œâ”€â”€ dbt/
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ quiz_summary.sql
â”‚       â”œâ”€â”€ student_performance.sql
â”‚       â””â”€â”€ class_analytics.sql
â”‚
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ powerbi/
â”‚   â””â”€â”€ streamlit_app.py
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ SRS.md
â”‚
â””â”€â”€ README.md
```

---

# ğŸ“˜ **6. Beginner â†’ Pro Curriculum (for your Intern)**

---

## ğŸ”° **Beginner (Week 1â€“2)**

* Python basic
* Pandas
* SQL basics
* EDA
* Data cleaning
* Accuracy/time calculations

---

## âš™ï¸ **Intermediate (Week 3â€“5)**

* ETL pipelines
* Airflow
* DBT
* Data modeling (star schema)
* BI dashboard basics

---

## ğŸš€ **Advanced (Week 6â€“8)**

* Kafka ingestion
* PySpark
* Real-time analytics
* Complex SQL (window functions)
* ML basics
* Feature engineering

---

## ğŸ§  **Pro (Week 9â€“12)**

* ML difficulty scoring
* LLM scoring of question quality
* Recommendation engine
* Production-grade monitoring
* API development
* Scaling data pipeline
